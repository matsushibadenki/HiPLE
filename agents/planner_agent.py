# path: ./agents/planner_agent.py
# title: Hierarchical PlannerAgent with Performance-Awareness
# description: ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹æƒ…å ±ã‚’è€ƒæ…®ã—ã¦ã€ä»–ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã¸ã®ç›¸è«‡ã‚’å«ã‚€éšŽå±¤çš„ãªè¨ˆç”»ã‚’ç”Ÿæˆã™ã‚‹ã€‚

import json
import re
from typing import List, Optional
from llama_cpp.llama_types import ChatCompletionRequestMessage
from domain.schemas import Plan, SubTask, ExpertModel, Milestone
from agents.base_agent import BaseAgent

class PlannerAgent(BaseAgent):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã‚’åˆ†æžã—ã€éšŽå±¤çš„ãªè¨ˆç”»ï¼ˆPlanï¼‰ã‚’ç”Ÿæˆã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (HiPLE-P)
    ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ã‚‚è€ƒæ…®ã™ã‚‹
    """
    def execute(
        self,
        prompt: str,
        experts: List[ExpertModel],
        failed_plan: Optional[Plan] = None,
        validation_error: Optional[str] = None,
        performance_summary: Optional[str] = None # è¿½åŠ 
    ) -> Plan:
        planner_expert = self._find_planner_expert(experts)
        expert_descriptions = self._format_expert_descriptions(experts)

        # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†“ä¿®æ­£é–‹å§‹â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
        system_prompt = self._build_system_prompt(expert_descriptions, performance_summary)
        # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†‘ä¿®æ­£çµ‚ã‚ã‚Šâ—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
        user_prompt = self._build_user_prompt(prompt, validation_error, failed_plan)
        
        messages: List[ChatCompletionRequestMessage] = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        raw_response = self._query_llm(planner_expert, messages)
        
        return self._parse_plan_from_response(raw_response, prompt, planner_expert)

    def _find_planner_expert(self, experts: List[ExpertModel]) -> ExpertModel:
        # æ€è€ƒã®ä¸­å¿ƒã¯HRMãŒæ‹…ã†
        for expert in experts:
            if expert.name.lower() == "hrm":
                return expert
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        for expert in experts:
            if expert.chat_format != "diffusion": return expert
        raise ValueError("åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†“ä¿®æ­£é–‹å§‹â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
    def _build_system_prompt(self, expert_descriptions: str, performance_summary: Optional[str]) -> str:
        prompt_header = """ã‚ãªãŸã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ›–æ˜§ãªè¦æ±‚ã‚’æ§‹é€ åŒ–ã•ã‚ŒãŸéšŽå±¤çš„è¨ˆç”»ã«å¤‰æ›ã™ã‚‹ã€è¶…å„ªç§€ãªAIãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒžãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§ã™ã€‚

# ã‚ãªãŸã®ã‚¿ã‚¹ã‚¯
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã¨ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹å®Ÿç¸¾ã‚’åˆ†æžã—ã€ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦JSONå½¢å¼ã®å®Ÿè¡Œè¨ˆç”»ã‚’ç«‹æ¡ˆã—ã¦ãã ã•ã„ã€‚

1.  **éšŽå±¤åŒ–**: æ€è€ƒã‚’3ã¤ã®ãƒ¬ãƒ™ãƒ«ï¼ˆL1: å…¨ä½“ç›®æ¨™, L2: ãƒžã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³, L3: ã‚µãƒ–ã‚¿ã‚¹ã‚¯ï¼‰ã«åˆ†è§£ã—ã¾ã™ã€‚
2.  **ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆé¸å®š (æœ€é‡è¦)**: å„ã‚¿ã‚¹ã‚¯ã«æœ€é©ãªã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚’ `expert_name` ã«å‰²ã‚Šå½“ã¦ã¦ãã ã•ã„ã€‚**ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ã‚µãƒžãƒªãƒ¼ã‚’æœ€å„ªå…ˆã®åˆ¤æ–­ææ–™ã¨ã—ã€ã‚¹ã‚³ã‚¢ãŒé«˜ãã€ã‚¿ã‚¹ã‚¯å†…å®¹ã«é©ã—ãŸã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚’é¸æŠž**ã—ã¦ãã ã•ã„ã€‚
3.  **æ„å‘³æ§‹é€ ã®å®šç¾©**: å„ã‚µãƒ–ã‚¿ã‚¹ã‚¯ï¼ˆL3ï¼‰ã«ã¯ã€ãã®ã‚¿ã‚¹ã‚¯ã®æœ¬è³ªçš„ãªæ„å‘³ã‚’å‡ç¸®ã—ãŸçŸ­ã„èª¬æ˜Žæ–‡ `ssv_description` ã‚’å¿…ãšè¨­å®šã—ã¦ãã ã•ã„ã€‚
4.  **ã‚³ãƒ³ã‚µãƒ«ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³**: ã‚¿ã‚¹ã‚¯ã®å“è³ªå‘ä¸Šã®ãŸã‚ã€è¤‡æ•°ã®å°‚é–€çŸ¥è­˜ãŒå¿…è¦ã ã¨åˆ¤æ–­ã—ãŸå ´åˆã€`consultation_experts`ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«åŠ©è¨€ã‚’æ±‚ã‚ã‚‹ã¹ãã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆåã®ãƒªã‚¹ãƒˆã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚
"""

        experts_section = f"""
# åˆ©ç”¨å¯èƒ½ãªã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ
{expert_descriptions}
"""
        
        performance_section = f"""
# ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹å®Ÿç¸¾ (æœ€é‡è¦å‚è€ƒæƒ…å ±)
{performance_summary if performance_summary else "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹è¨˜éŒ²ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®èª¬æ˜Žã«åŸºã¥ã„ã¦åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚"}
"""

        json_format_section = """
# JSONå‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆ (åŽ³å®ˆ)
```json
{
  "overall_goal": "ï¼ˆL1: ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã‚’ä¸€æ–‡ã§è¡¨ç¾ã—ãŸæœ€çµ‚ç›®æ¨™ï¼‰",
  "milestones": [
    {
      "milestone_id": 1,
      "title": "ï¼ˆL2: æœ€åˆã®ãƒžã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã®ã‚¿ã‚¤ãƒˆãƒ«ï¼‰",
      "description": "ï¼ˆã“ã®ãƒžã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã®ç›®çš„ï¼‰"
    }
  ],
  "tasks": [
    {
      "task_id": 1,
      "milestone_id": 1,
      "description": "ï¼ˆL3: å®Ÿè¡Œã™ã¹ãå…·ä½“çš„ãªã‚¿ã‚¹ã‚¯å†…å®¹ï¼‰",
      "expert_name": "ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ã¨é©æ€§ã‚’è€ƒæ…®ã—ã¦é¸ã‚“ã ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆåï¼‰",
      "ssv_description": "ï¼ˆã‚¿ã‚¹ã‚¯ã®æ„å‘³ã®æ ¸ã‚’è¨˜è¿°ã—ãŸçŸ­ã„èª¬æ˜Žæ–‡ï¼‰",
      "consultation_experts": ["ï¼ˆåŠ©è¨€ã‚’æ±‚ã‚ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆå1ï¼‰"],
      "dependencies": []
    }
  ]
}
```
"""

        rules_section = """
# ãƒ«ãƒ¼ãƒ«
- **ID**: `milestone_id`ã¨`task_id`ã¯1ã‹ã‚‰å§‹ã¾ã‚‹é€£ç•ªã«ã—ã¦ãã ã•ã„ã€‚
- **ä¾å­˜é–¢ä¿‚**: `dependencies`ã«ã¯å…ˆè¡Œã‚¿ã‚¹ã‚¯ã®`task_id`ã‚’ãƒªã‚¹ãƒˆã§æŒ‡å®šã—ã¾ã™ã€‚
- **å ±å‘Šã‚¿ã‚¹ã‚¯**: è¤‡é›‘ãªè¦æ±‚ã®å ´åˆã€æœ€å¾Œã«'Reporter'ã‚’é…ç½®ã—ã€æœ€çµ‚å ±å‘Šæ›¸ã‚’ä½œæˆã•ã›ã¦ãã ã•ã„ã€‚
- **å˜ç´”ãªè¦æ±‚**: å˜ç´”ãªæŒ¨æ‹¶ã‚„è³ªå•ã®å ´åˆã€ãƒžã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã¯1ã¤ã€ã‚¿ã‚¹ã‚¯ã‚‚1ã¤ã ã‘ç”Ÿæˆã—ã¾ã™ã€‚
"""
        return prompt_header + experts_section + performance_section + json_format_section + rules_section
    # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†‘ä¿®æ­£çµ‚ã‚ã‚Šâ—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸

    def _build_user_prompt(self, prompt: str, validation_error: Optional[str], failed_plan: Optional[Plan]) -> str:
        user_prompt = f"ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã«å¯¾ã™ã‚‹éšŽå±¤çš„å®Ÿè¡Œè¨ˆç”»ã‚’JSONå½¢å¼ã§ä½œæˆã—ã¦ãã ã•ã„:\n\nè¦æ±‚: \"{prompt}\""
        if validation_error:
            user_prompt += f"\n\n#ã€æœ€é‡è¦ã€‘å‰å›žã®è¨ˆç”»ã¯ä»¥ä¸‹ã®æ¤œè¨¼ã‚¨ãƒ©ãƒ¼ã§å¤±æ•—ã—ã¾ã—ãŸã€‚ã“ã®ã‚¨ãƒ©ãƒ¼ã‚’å®Œå…¨ã«ä¿®æ­£ã—ã€è«–ç†çš„ã«ä¸€è²«ã—ãŸæ–°ã—ã„è¨ˆç”»ã‚’ç«‹ã¦ç›´ã—ã¦ãã ã•ã„ã€‚\nã‚¨ãƒ©ãƒ¼å†…å®¹: {validation_error}"
        if failed_plan:
            user_prompt += f"\n\n# è­¦å‘Š\nå‰å›žã®è¨ˆç”»ã¯å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸã€‚å†…å®¹ã‚’æ ¹æœ¬çš„ã«è¦‹ç›´ã—ã€æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§è¨ˆç”»ã‚’ç«‹ã¦ç›´ã—ã¦ãã ã•ã„ã€‚"
        return user_prompt

    def _parse_plan_from_response(self, raw_response: str, original_prompt: str, planner_expert: ExpertModel) -> Plan:
        try:
            print(f"--- Hierarchical Planner Raw Response ---\n{raw_response}\n--------------------------")
            json_match = re.search(r'```json\s*(\{[\s\S]*?\})\s*```', raw_response, re.DOTALL)
            if not json_match:
                start_index = raw_response.find('{')
                end_index = raw_response.rfind('}')
                if start_index == -1 or end_index == -1:
                    raise json.JSONDecodeError("å¿œç­”ã«JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚", raw_response, 0)
                plan_json_str = raw_response[start_index:end_index + 1]
            else:
                plan_json_str = json_match.group(1)
            
            plan_data = json.loads(plan_json_str)

            milestones = [Milestone(**m) for m in plan_data.get("milestones", [])]
            tasks_data = plan_data.get("tasks", [])
            if not tasks_data:
                 # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå˜ç´”ãªã‚¿ã‚¹ã‚¯ã¨ã—ã¦ç”Ÿæˆ
                 return self._create_fallback_plan(original_prompt, planner_expert)

            for t in tasks_data:
                if "ssv_description" not in t or not t["ssv_description"]:
                    t["ssv_description"] = t["description"]
                if "consultation_experts" not in t:
                    t["consultation_experts"] = []

            tasks = [SubTask(**t) for t in tasks_data]

            return Plan(
                original_prompt=original_prompt,
                overall_goal=plan_data.get("overall_goal", "N/A"),
                milestones=milestones,
                tasks=tasks
            )
        except (json.JSONDecodeError, TypeError, ValueError, AttributeError) as e:
            print(f"âŒ éšŽå±¤çš„è¨ˆç”»ã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            print(f"ðŸ” ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç›´æŽ¥å®Ÿè¡Œã—ã¾ã™ã€‚")
            return self._create_fallback_plan(original_prompt, planner_expert)

    def _create_fallback_plan(self, original_prompt: str, expert: ExpertModel) -> Plan:
        """ãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã«ã€å˜ç´”ãªç›´æŽ¥å®Ÿè¡Œè¨ˆç”»ã‚’ä½œæˆã™ã‚‹"""
        task = SubTask(
            task_id=1,
            milestone_id=1,
            description=original_prompt,
            expert_name=expert.name,
            ssv_description=original_prompt,
            consultation_experts=[],
            dependencies=[]
        )
        milestone = Milestone(milestone_id=1, title="Direct Execution", description="Execute the user's prompt directly.")
        return Plan(
            original_prompt=original_prompt,
            overall_goal=original_prompt,
            milestones=[milestone],
            tasks=[task]
        )

    def _format_expert_descriptions(self, experts: List[ExpertModel]) -> str:
        return "\n".join([f"- **{e.name}**: {e.description}" for e in experts if e.name.lower() != "reporter"])
