# path: ./agents/planner_agent.py
# title: Hierarchical PlannerAgent (HiPLE-P)
# description: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã‚’åˆ†æžã—ã€éšŽå±¤çš„ãªå®Ÿè¡Œè¨ˆç”»ï¼ˆL1, L2, L3ï¼‰ã‚’ç”Ÿæˆã™ã‚‹ã€‚

import json
import re
from typing import List, Optional
from llama_cpp.llama_types import ChatCompletionRequestMessage
from domain.schemas import Plan, SubTask, ExpertModel, Milestone
from agents.base_agent import BaseAgent

class PlannerAgent(BaseAgent):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã‚’åˆ†æžã—ã€éšŽå±¤çš„ãªè¨ˆç”»ï¼ˆPlanï¼‰ã‚’ç”Ÿæˆã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (HiPLE-P)
    """
    def execute(
        self,
        prompt: str,
        experts: List[ExpertModel],
        failed_plan: Optional[Plan] = None,
        validation_error: Optional[str] = None
    ) -> Plan:
        planner_expert = self._find_planner_expert(experts)
        expert_descriptions = self._format_expert_descriptions(experts)

        system_prompt = self._build_system_prompt(expert_descriptions)
        user_prompt = self._build_user_prompt(prompt, validation_error, failed_plan)
        
        messages: List[ChatCompletionRequestMessage] = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        raw_response = self._query_llm(planner_expert, messages)
        
        return self._parse_plan_from_response(raw_response, prompt, planner_expert)

    def _find_planner_expert(self, experts: List[ExpertModel]) -> ExpertModel:
        # æ€è€ƒã®ä¸­å¿ƒã¯HRMãŒæ‹…ã†
        for expert in experts:
            if expert.name.lower() == "hrm":
                return expert
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        for expert in experts:
            if expert.chat_format != "diffusion": return expert
        raise ValueError("åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    def _build_system_prompt(self, expert_descriptions: str) -> str:
        return f"""ã‚ãªãŸã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ›–æ˜§ãªè¦æ±‚ã‚’æ§‹é€ åŒ–ã•ã‚ŒãŸéšŽå±¤çš„è¨ˆç”»ã«å¤‰æ›ã™ã‚‹ã€è¶…å„ªç§€ãªAIãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒžãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§ã™ã€‚

# ã‚ãªãŸã®ã‚¿ã‚¹ã‚¯
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã‚’åˆ†æžã—ã€ä»¥ä¸‹ã®3ã¤ã®ãƒ¬ãƒ™ãƒ«ã§æ§‹æˆã•ã‚Œã‚‹JSONå½¢å¼ã®å®Ÿè¡Œè¨ˆç”»ã‚’ç«‹æ¡ˆã—ã¦ãã ã•ã„ã€‚

1.  **L1: å…¨ä½“ç›®æ¨™ (overall_goal)**: ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã®æœ€çµ‚çš„ãªã‚´ãƒ¼ãƒ«ã‚’ã€ä¸€æ–‡ã§æ˜Žç¢ºã«å®šç¾©ã—ã¾ã™ã€‚
2.  **L2: ä¸»è¦ãƒžã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ (milestones)**: å…¨ä½“ç›®æ¨™ã‚’é”æˆã™ã‚‹ãŸã‚ã®ã€è«–ç†çš„ãªä¸­é–“ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¤‡æ•°å®šç¾©ã—ã¾ã™ã€‚å„ãƒžã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã¯ã€Œç« ã€ã®ã‚ˆã†ãªã‚‚ã®ã§ã™ã€‚
3.  **L3: å…·ä½“çš„ãªã‚µãƒ–ã‚¿ã‚¹ã‚¯ (tasks)**: å„ãƒžã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã‚’é”æˆã™ã‚‹ãŸã‚ã®ã€å®Ÿè¡Œå¯èƒ½ãªå…·ä½“çš„ãªã‚¿ã‚¹ã‚¯ã‚’å®šç¾©ã—ã¾ã™ã€‚å„ã‚¿ã‚¹ã‚¯ã«ã¯ã€æœ€é©ãªã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚’1åå‰²ã‚Šå½“ã¦ã¾ã™ã€‚

# åŽ³å®ˆã™ã¹ããƒ«ãƒ¼ãƒ«
- **éšŽå±¤æ§‹é€ **: å¿…ãš `overall_goal`, `milestones`, `tasks` ã®3éšŽå±¤ã§è¨ˆç”»ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
- **IDã®é€£ç•ª**: `milestone_id` ã¨ `task_id` ã¯å¿…ãš1ã‹ã‚‰å§‹ã¾ã‚‹é€£ç•ªã«ã—ã¦ãã ã•ã„ã€‚
- **ã‚¿ã‚¹ã‚¯ã¨ãƒžã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã®ç´ä»˜ã‘**: å„ã‚¿ã‚¹ã‚¯ã«ã¯ã€ãã‚ŒãŒå±žã™ã‚‹ `milestone_id` ã‚’å¿…ãšè¨­å®šã—ã¦ãã ã•ã„ã€‚
- **ä¾å­˜é–¢ä¿‚**: ã‚¿ã‚¹ã‚¯ã® `dependencies` ã«ã¯ã€ãã®ã‚¿ã‚¹ã‚¯ãŒä¾å­˜ã™ã‚‹å…ˆè¡Œã‚¿ã‚¹ã‚¯ã® `task_id` ã‚’ãƒªã‚¹ãƒˆã§æŒ‡å®šã—ã¾ã™ã€‚
- **å ±å‘Šã‚¿ã‚¹ã‚¯**: è¤‡é›‘ãªè¦æ±‚ã®å ´åˆã€æœ€å¾Œã®ãƒžã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã®æœ€å¾Œã®ã‚¿ã‚¹ã‚¯ã¨ã—ã¦ã€å¿…ãš 'Reporter' ã‚’é…ç½®ã—ã€ãã‚Œã¾ã§ã®å…¨ã‚¿ã‚¹ã‚¯ã‚’çµ±åˆã—ã¦æœ€çµ‚å ±å‘Šæ›¸ã‚’ä½œæˆã•ã›ã¦ãã ã•ã„ã€‚
- **å˜ç´”ãªè¦æ±‚**: ã€Œã“ã‚“ã«ã¡ã¯ã€ã®ã‚ˆã†ãªå˜ç´”ãªæŒ¨æ‹¶ã‚„è³ªå•ã®å ´åˆã€ãƒžã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã¯1ã¤ã€ã‚¿ã‚¹ã‚¯ã‚‚1ã¤ã ã‘ç”Ÿæˆã—ã¾ã™ã€‚Reporterã¯ä¸è¦ã§ã™ã€‚
- **ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®èƒ½åŠ›**: ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã¯ä»¥ä¸‹ã®èƒ½åŠ›ã—ã‹æŒã¡ã¾ã›ã‚“ã€‚Webæ¤œç´¢ã‚„ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æƒ…å ±ã®å–å¾—ã¯ã§ãã¾ã›ã‚“ã€‚
{expert_descriptions}

# å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆ (JSONå½¢å¼ã®ã¿)
```json
{{
  "overall_goal": "ï¼ˆL1: ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã‚’ä¸€æ–‡ã§è¡¨ç¾ã—ãŸæœ€çµ‚ç›®æ¨™ï¼‰",
  "milestones": [
    {{
      "milestone_id": 1,
      "title": "ï¼ˆL2: æœ€åˆã®ãƒžã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã®ã‚¿ã‚¤ãƒˆãƒ«ï¼‰",
      "description": "ï¼ˆã“ã®ãƒžã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã®ç›®çš„ï¼‰"
    }}
  ],
  "tasks": [
    {{
      "task_id": 1,
      "milestone_id": 1,
      "description": "ï¼ˆL3: å®Ÿè¡Œã™ã¹ãå…·ä½“çš„ãªã‚¿ã‚¹ã‚¯å†…å®¹ï¼‰",
      "expert_name": "ï¼ˆã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆåï¼‰",
      "dependencies": []
    }}
  ]
}}
```"""

    def _build_user_prompt(self, prompt: str, validation_error: Optional[str], failed_plan: Optional[Plan]) -> str:
        user_prompt = f"ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã«å¯¾ã™ã‚‹éšŽå±¤çš„å®Ÿè¡Œè¨ˆç”»ã‚’JSONå½¢å¼ã§ä½œæˆã—ã¦ãã ã•ã„:\n\nè¦æ±‚: \"{prompt}\""
        if validation_error:
            user_prompt += f"\n\n# è­¦å‘Š\nå‰å›žã®è¨ˆç”»ã¯æ¤œè¨¼ã‚¨ãƒ©ãƒ¼ã§å¤±æ•—ã—ã¾ã—ãŸ: {validation_error}\nã“ã®ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã—ã€æ­£ã—ã„è¨ˆç”»ã‚’ç«‹ã¦ç›´ã—ã¦ãã ã•ã„ã€‚"
        if failed_plan:
            user_prompt += f"\n\n# è­¦å‘Š\nå‰å›žã®è¨ˆç”»ã¯å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸã€‚å†…å®¹ã‚’æ ¹æœ¬çš„ã«è¦‹ç›´ã—ã€æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§è¨ˆç”»ã‚’ç«‹ã¦ç›´ã—ã¦ãã ã•ã„ã€‚"
        return user_prompt

    def _parse_plan_from_response(self, raw_response: str, original_prompt: str, planner_expert: ExpertModel) -> Plan:
        try:
            print(f"--- Hierarchical Planner Raw Response ---\n{raw_response}\n--------------------------")
            json_match = re.search(r'```json\s*(\{[\s\S]*?\})\s*```', raw_response, re.DOTALL)
            if not json_match:
                start_index = raw_response.find('{')
                end_index = raw_response.rfind('}')
                if start_index == -1 or end_index == -1:
                    raise json.JSONDecodeError("å¿œç­”ã«JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚", raw_response, 0)
                plan_json_str = raw_response[start_index:end_index + 1]
            else:
                plan_json_str = json_match.group(1)
            
            plan_data = json.loads(plan_json_str)

            milestones = [Milestone(**m) for m in plan_data.get("milestones", [])]
            tasks = [SubTask(**t) for t in plan_data.get("tasks", [])]

            return Plan(
                original_prompt=original_prompt,
                overall_goal=plan_data.get("overall_goal", "N/A"),
                milestones=milestones,
                tasks=tasks
            )
        except (json.JSONDecodeError, TypeError, ValueError, AttributeError) as e:
            print(f"âŒ éšŽå±¤çš„è¨ˆç”»ã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            print(f"ðŸ” ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç›´æŽ¥å®Ÿè¡Œã—ã¾ã™ã€‚")
            task = SubTask(
                task_id=1,
                milestone_id=1,
                description=original_prompt,
                expert_name=planner_expert.name,
                dependencies=[]
            )
            milestone = Milestone(milestone_id=1, title="Direct Execution", description="Execute the user's prompt directly.")
            return Plan(
                original_prompt=original_prompt,
                overall_goal=original_prompt,
                milestones=[milestone],
                tasks=[task]
            )

    def _format_expert_descriptions(self, experts: List[ExpertModel]) -> str:
        return "\n".join([f"- **{e.name}**: {e.description}" for e in experts if e.name.lower() != "reporter"])