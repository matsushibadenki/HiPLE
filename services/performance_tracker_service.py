# path: ./services/performance_tracker_service.py
# title: Performance Tracker Service (with Robust Fallback)
# description: AIã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ã‚ˆã‚Šæ­£ç¢ºã«è¿½è·¡ãƒ»è©•ä¾¡ã—ã€æœ€é©ãªã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚’é¸æŠã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ­ã‚¸ãƒƒã‚¯ã‚’å¼·åŒ–ã€‚

import time
from typing import Dict, Optional, List
from domain.evaluation import PerformanceMetrics
from domain.schemas import ExpertModel

class PerformanceTrackerService:
    """
    ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è¨˜éŒ²ãƒ»ç®¡ç†ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹
    """
    def __init__(self):
        self.performance_records: Dict[str, PerformanceMetrics] = {}

    def update_performance(
        self,
        expert_name: str,
        execution_time: float,
        success: bool
    ) -> None:
        """
        æŒ‡å®šã•ã‚ŒãŸã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ›´æ–°ã™ã‚‹
        """
        if expert_name not in self.performance_records:
            self.performance_records[expert_name] = PerformanceMetrics()

        record = self.performance_records[expert_name]
        
        # å®Ÿè¡Œæ™‚é–“ã¯æˆåŠŸãƒ»å¤±æ•—ã«é–¢ã‚ã‚‰ãšè¨˜éŒ²
        record.total_execution_time_all += execution_time
        
        if success:
            record.success_count += 1
            record.total_execution_time_on_success += execution_time
        else:
            record.failure_count += 1

        self._recalculate_score(expert_name)
        print(f"ğŸ“Š Performance updated for '{expert_name}': Score={record.score:.2f}, SuccessRate={record.success_rate:.2f}, AvgTime={record.average_execution_time:.2f}s")


    def _recalculate_score(self, expert_name: str) -> None:
        """
        ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ã‚¹ã‚³ã‚¢ã‚’å†è¨ˆç®—ã™ã‚‹
        ã‚¹ã‚³ã‚¢ = æˆåŠŸç‡ã‚’é‡è¦–ã—ã¤ã¤ã€å®Ÿè¡Œæ™‚é–“ãŒçŸ­ã„ã»ã©é«˜è©•ä¾¡
        """
        record = self.performance_records.get(expert_name)
        if not record or record.total_runs == 0:
            return

        # å…¨ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®å¹³å‡å®Ÿè¡Œæ™‚é–“ã‚’è¨ˆç®—ï¼ˆã‚¹ã‚³ã‚¢æ­£è¦åŒ–ã®ãŸã‚ï¼‰
        all_avg_times = [
            r.average_execution_time
            for r in self.performance_records.values()
            if r.total_runs > 0
        ]
        
        # ã‚¼ãƒ­é™¤ç®—ã¨ç©ºãƒªã‚¹ãƒˆã®ã‚¨ãƒ©ãƒ¼ã‚’å›é¿
        max_avg_time = max(all_avg_times) if all_avg_times else 1.0
        if max_avg_time == 0: max_avg_time = 1.0
        
        normalized_time = record.average_execution_time / max_avg_time
        time_penalty = min(normalized_time, 1.0)

        # ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆæˆåŠŸç‡ã‚’ä¸»è»¸ã«ã€å®Ÿè¡Œæ™‚é–“ãŒçŸ­ã„ã»ã©ãƒœãƒ¼ãƒŠã‚¹ï¼‰
        record.score = record.success_rate * (1.0 - (time_penalty * 0.2))


    def get_best_expert(self, experts: List[ExpertModel], task_type: str = "general") -> Optional[ExpertModel]:
        """
        ç¾åœ¨æœ€ã‚‚ã‚¹ã‚³ã‚¢ã®é«˜ã„ã€åˆ©ç”¨å¯èƒ½ãªã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚’è¿”ã™ã€‚
        é©åˆ‡ãªã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€å®‰å®šã—ãŸãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’æä¾›ã™ã‚‹ã€‚
        """
        best_expert: Optional[ExpertModel] = None
        highest_score = -1.0

        # è©•ä¾¡è¨˜éŒ²ãŒã‚ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ã¿ã‚’å¯¾è±¡
        eligible_experts = [
            e for e in experts if e.name in self.performance_records and e.chat_format != "diffusion"
        ]

        # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†“ä¿®æ­£é–‹å§‹â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
        # ã‚¹ã‚³ã‚¢ãŒ0ã‚ˆã‚Šå¤§ãã„ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ä¸­ã‹ã‚‰æœ€é©è§£ã‚’æ¢ã™
        for expert in eligible_experts:
            score = self.performance_records[expert.name].score
            if score > highest_score:
                highest_score = score
                best_expert = expert
        
        # ã‚¹ã‚³ã‚¢ã«åŸºã¥ãæœ€é©ãªã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã¯ãã‚Œã‚’è¿”ã™
        if best_expert:
            print(f"ğŸ† Best expert selected for '{task_type}': '{best_expert.name}' (Score: {highest_score:.2f})")
            return best_expert

        # é©åˆ‡ãªã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ã€å …ç‰¢ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥
        print(f"ğŸŸ¡ No expert with a positive score for '{task_type}'. Using fallback strategy.")
        
        # 1. æ€è€ƒã®ä¸­å¿ƒã§ã‚ã‚‹HRMã‚’è©¦ã™
        hrm_expert = next((e for e in experts if e.name.lower() == "hrm"), None)
        if hrm_expert:
            print("â†ªï¸ Fallback to default reasoner: 'HRM'")
            return hrm_expert
            
        # 2. æ±ç”¨çš„ãªJambaã‚’è©¦ã™
        jamba_expert = next((e for e in experts if e.name.lower() == "jamba"), None)
        if jamba_expert:
            print("â†ªï¸ Fallback to generalist: 'Jamba'")
            return jamba_expert

        # 3. ãã‚Œã§ã‚‚è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€æœ€åˆã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚’è¿”ã™
        return next((e for e in experts if e.chat_format != "diffusion"), None)
        # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†‘ä¿®æ­£çµ‚ã‚ã‚Šâ—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸

    def get_performance_summary(self) -> str:
        """
        å…¨ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼ã‚’æ–‡å­—åˆ—ã¨ã—ã¦è¿”ã™
        """
        summary_lines = ["# Expert Performance Summary"]
        if not self.performance_records:
            return "# Expert Performance Summary\nNo performance records yet."
            
        for name, record in sorted(self.performance_records.items(), key=lambda item: item[1].score, reverse=True):
            summary_lines.append(
                f"- **{name}**: "
                f"Score={record.score:.2f}, "
                f"SuccessRate={record.success_rate * 100:.1f}%, "
                f"AvgTime={record.average_execution_time:.2f}s, "
                f"Runs={record.total_runs}"
            )
        return "\n".join(summary_lines)
