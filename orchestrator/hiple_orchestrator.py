# path: ./orchestrator/hiple_orchestrator.py
# title: Self-Correcting Orchestrator with Stabilized Simple Task Processing
# description: å˜ç´”ãªã‚¿ã‚¹ã‚¯ã®å‡¦ç†ã‚’ã€ä¸å®‰å®šãªJambaã§ã¯ãªãã€å¸¸ã«å®‰å®šã—ãŸHRMã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆãŒæ‹…å½“ã™ã‚‹ã‚ˆã†ã«ä¿®æ­£ã€‚

import traceback
from typing import Dict, List, Tuple, Any, Optional
from domain.model_manager import ModelManager
from domain.schemas import SubTask, Plan, ExpertModel, Milestone
from agents.planner_agent import PlannerAgent
from agents.generator_agent import GeneratorAgent
from agents.reporter_agent import ReporterAgent
from agents.tool_router_agent import ToolRouterAgent
from agents.wikipedia_agent import WikipediaAgent
from services.retrieval_service import RetrievalService
from services.plan_evaluation_service import PlanEvaluationService

class HipleOrchestrator:
    """
    HiPLEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«åŸºã¥ãã€æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹å…¨ä½“ã‚’ç®¡ç†ã™ã‚‹ã€‚
    ToolRouterAgentã‚’ç”¨ã„ã¦ã€è¨ˆç”»ç«‹æ¡ˆã‚„ãƒ„ãƒ¼ãƒ«åˆ©ç”¨ã‚’å‹•çš„ã«åˆ‡ã‚Šæ›¿ãˆã‚‹ã€‚
    """
    def __init__(
        self,
        model_manager: ModelManager,
        planner_agent: PlannerAgent,
        generator_agent: GeneratorAgent,
        reporter_agent: ReporterAgent,
        tool_router_agent: ToolRouterAgent,
        wikipedia_agent: WikipediaAgent,
        retrieval_service: RetrievalService,
        plan_evaluation_service: PlanEvaluationService,
    ):
        self.model_manager = model_manager
        self.planner_agent = planner_agent
        self.generator_agent = generator_agent
        self.reporter_agent = reporter_agent
        self.tool_router_agent = tool_router_agent
        self.wikipedia_agent = wikipedia_agent
        self.retrieval_service = retrieval_service
        self.plan_evaluation_service = plan_evaluation_service
        self.max_replanning_attempts = 2

    def process_task(self, prompt: str) -> str:
        """
        ã‚¿ã‚¹ã‚¯å‡¦ç†ã®ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã€‚
        """
        print(f"â–¶ï¸ HiPLEã‚¿ã‚¹ã‚¯é–‹å§‹: {prompt}")
        try:
            active_experts = self.model_manager.get_all_experts()
            if not active_experts: return "ã‚¨ãƒ©ãƒ¼: åˆ©ç”¨å¯èƒ½ãªã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆãŒã„ã¾ã›ã‚“ã€‚"

            print("\n--- Phase 0: Routing ---")
            task_type = self.tool_router_agent.execute(prompt, active_experts)
            print(f"ğŸ§  ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°çµæœ: {task_type.upper()}")

            if task_type == "wikipedia":
                return self.wikipedia_agent.execute(prompt)
            elif task_type == "web_search":
                return "ã‚¦ã‚§ãƒ–æ¤œç´¢æ©Ÿèƒ½ã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™ã€‚"
            elif task_type == "no_tool":
                return self._process_simple_task(prompt, active_experts)
            else: # complex_task
                return self._process_complex_task(prompt, active_experts)

        except Exception as e:
            traceback.print_exc()
            return f"è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

    def _process_simple_task(self, prompt: str, experts: List[ExpertModel]) -> str:
        """
        å˜ç´”ãªã‚¿ã‚¹ã‚¯ã‚’ç›´æ¥å®Ÿè¡Œã™ã‚‹ã€‚
        """
        # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†“ä¿®æ­£é–‹å§‹â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
        print("\n--- Direct Generation (using HRM for stability) ---")
        # ä¸å®‰å®šãªJambaã®ä½¿ç”¨ã‚’ã‚„ã‚ã€å¸¸ã«å®‰å®šã—ã¦ã„ã‚‹HRMã‚’å˜ç´”ãªå¿œç­”ã«ä½¿ç”¨ã™ã‚‹
        expert = self.model_manager.get_expert("HRM")
        if not expert:
            return "ã‚¨ãƒ©ãƒ¼: å˜ç´”å¿œç­”ç”¨ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ'HRM'ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®å¯¾è©±ã«é©ã—ãŸã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨­å®š
        expert.system_prompt = "ã‚ãªãŸã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«èª å®Ÿã‹ã¤ç°¡æ½”ã«ç­”ãˆã‚‹ã€å„ªç§€ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
        # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†‘ä¿®æ­£çµ‚ã‚ã‚Šâ—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
        
        task = SubTask(
            task_id=1,
            description=prompt,
            expert_name=expert.name,
            ssv_description=prompt,
            consultation_experts=[]
        )
        context = self._build_minimal_context(prompt)

        return self.generator_agent.execute(task, expert, context, experts)

    def _process_complex_task(self, prompt: str, experts: List[ExpertModel]) -> str:
        """
        è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ã€éšå±¤çš„ãªè¨ˆç”»ã‚’ç«‹ã¦ã€æ¤œè¨¼ã—ã€å®Ÿè¡Œã™ã‚‹ã€‚
        """
        failed_plan: Optional[Plan] = None
        validation_error: Optional[str] = None

        for attempt in range(self.max_replanning_attempts):
            print(f"\n--- Phase 1: Hierarchical Planning (Attempt {attempt + 1}) ---")
            current_plan = self.planner_agent.execute(prompt, experts, failed_plan, validation_error)

            print(f"L1 (Goal): {current_plan.overall_goal}")
            for m in current_plan.milestones:
                print(f"L2 (Milestone {m.milestone_id}): {m.title}")

            is_struct_valid, struct_error = self._validate_plan_structure(current_plan, experts)
            if not is_struct_valid:
                print(f"âš ï¸ è¨ˆç”»ã®æ§‹é€ æ¤œè¨¼ã«å¤±æ•—: {struct_error}")
                validation_error = f"æ§‹é€ çš„ã‚¨ãƒ©ãƒ¼: {struct_error}"
                failed_plan = current_plan
                continue

            print("âœ… è¨ˆç”»ã®æ§‹é€ ã¯å¦¥å½“ã§ã™ã€‚")

            is_semantic_valid, semantic_error = self.plan_evaluation_service.check_semantic_coherence(current_plan.tasks)
            if not is_semantic_valid:
                print(f"âš ï¸ è¨ˆç”»ã®æ„å‘³çš„ä¸€è²«æ€§æ¤œè¨¼ã«å¤±æ•—: {semantic_error}")
                validation_error = f"æ„å‘³çš„ä¸€è²«æ€§ã‚¨ãƒ©ãƒ¼: {semantic_error}"
                failed_plan = current_plan
                continue

            print("âœ… è¨ˆç”»ã®æ„å‘³çš„ä¸€è²«æ€§ã¯å¦¥å½“ã§ã™ã€‚")

            return self._execute_plan(current_plan, experts)

        print(f"âŒ {self.max_replanning_attempts}å›ã®å†è¨ˆç”»ã®è©¦è¡Œå¾Œã‚‚ã€æœ‰åŠ¹ãªè¨ˆç”»ã‚’ä½œæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return "ã‚¨ãƒ©ãƒ¼: å®Ÿè¡Œå¯èƒ½ãªè¨ˆç”»ã‚’ç«‹æ¡ˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…·ä½“çš„ã«ã—ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"

    def _execute_plan(self, plan: Plan, experts: List[ExpertModel]) -> str:
        """
        æ¤œè¨¼æ¸ˆã¿ã®è¨ˆç”»ã‚’å®Ÿè¡Œã™ã‚‹
        """
        self.retrieval_service.build_index(plan)

        print("\n--- Phase 2: Context-Aware Generation (HiPLE-G) ---")
        completed_tasks: Dict[int, SubTask] = {}

        worker_tasks = [t for t in plan.tasks if t.expert_name.lower() != 'reporter']

        while len(completed_tasks) < len(worker_tasks):
            executable_tasks = [t for t in worker_tasks if t.status == "pending" and all(d in completed_tasks for d in t.dependencies)]

            if not executable_tasks:
                if len(completed_tasks) < len(worker_tasks):
                    return "ã‚¨ãƒ©ãƒ¼: ã‚¿ã‚¹ã‚¯ã®ä¾å­˜é–¢ä¿‚ãŒå¾ªç’°ã—ã¦ã„ã‚‹ã‹ã€è¨ˆç”»ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚"
                break

            for task in executable_tasks:
                expert = self.model_manager.get_expert(task.expert_name)
                if not expert:
                    task.result = f"ã‚¨ãƒ©ãƒ¼: ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ '{task.expert_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
                    task.status = "failed"
                    completed_tasks[task.task_id] = task
                    continue

                context = self._build_context_for_task(task, plan, completed_tasks)

                print(f"\nâ–¶ï¸ Executing Task {task.task_id} ({task.expert_name.upper()}): {task.description}")
                task.status = "in_progress"
                task.result = self.generator_agent.execute(task, expert, context, experts)
                task.status = "completed"
                completed_tasks[task.task_id] = task
                print(f"âœ… Task {task.task_id} Completed.")

        reporter_tasks = [t for t in plan.tasks if t.expert_name.lower() == 'reporter']
        if reporter_tasks:
             print("\n--- Phase 3: Reporting ---")
             final_report = self.reporter_agent.execute(plan, experts)
             return final_report
        else:
            if not completed_tasks: return "ã‚¿ã‚¹ã‚¯ã¯å®Ÿè¡Œã•ã‚Œã¾ã—ãŸãŒã€çµæœãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
            last_task = max(completed_tasks.values(), key=lambda t: t.task_id)
            return last_task.result or "å®Œäº†ã—ã¾ã—ãŸãŒçµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚"

    def _validate_plan_structure(self, plan: Plan, experts: List[ExpertModel]) -> Tuple[bool, str]:
        if not plan.tasks: return False, "è¨ˆç”»ã«ã‚¿ã‚¹ã‚¯ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
        task_ids = {task.task_id for task in plan.tasks}
        milestone_ids = {m.milestone_id for m in plan.milestones}
        valid_expert_names = {expert.name.lower() for expert in experts}

        for task in plan.tasks:
            if task.expert_name.lower() not in valid_expert_names:
                return False, f"ã‚¿ã‚¹ã‚¯ {task.task_id} ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ '{task.expert_name}' ãŒä¸æ­£ã§ã™ã€‚"
            if task.milestone_id is not None and task.milestone_id not in milestone_ids:
                 return False, f"ã‚¿ã‚¹ã‚¯ {task.task_id} ã®ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ID '{task.milestone_id}' ãŒä¸æ­£ã§ã™ã€‚"
            for dep_id in task.dependencies:
                if dep_id not in task_ids:
                    return False, f"ã‚¿ã‚¹ã‚¯ {task.task_id} ã®ä¾å­˜å…ˆ {dep_id} ãŒä¸æ­£ã§ã™ã€‚"
        return True, "è¨ˆç”»ã¯æ§‹é€ çš„ã«å¦¥å½“ã§ã™ã€‚"

    def _build_context_for_task(self, task: SubTask, plan: Plan, completed_tasks: Dict[int, SubTask]) -> Dict[str, Any]:
        current_milestone = next((m for m in plan.milestones if m.milestone_id == task.milestone_id), None)
        dependency_results = ""
        if task.dependencies:
            for dep_id in sorted(task.dependencies):
                if dep_id in completed_tasks:
                    result = completed_tasks[dep_id].result
                    dependency_results += f"ã€å…ˆè¡Œã‚¿ã‚¹ã‚¯{dep_id}ã®çµæœã€‘:\n{result}\n\n"
        rag_results = self.retrieval_service.search(task.ssv_description, k=3)
        return {
            "original_prompt": plan.original_prompt,
            "overall_goal": plan.overall_goal,
            "milestone": current_milestone,
            "ssv_description": task.ssv_description,
            "dependency_results": dependency_results,
            "rag_results": rag_results
        }

    def _build_minimal_context(self, prompt: str) -> Dict[str, Any]:
        return {
            "original_prompt": prompt,
            "overall_goal": prompt,
            "milestone": Milestone(milestone_id=1, title="Direct Task", description=prompt),
            "dependency_results": "",
            "rag_results": []
        }